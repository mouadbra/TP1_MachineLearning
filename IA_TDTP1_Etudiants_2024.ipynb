{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64b0fab4",
      "metadata": {
        "id": "64b0fab4"
      },
      "source": [
        "# TD/TP 1 IA : Machine Learning\n",
        "\n",
        "Introduction\n",
        "\n",
        "I. Régression\n",
        "1. Données et traitement\n",
        "2. Régression linéaire\n",
        "2.1 Régression linéaire 1d\n",
        "2.2 Régression linéaire multi variable\n",
        "3. Régression polynomiale\n",
        "\n",
        "\n",
        "II. Classification\n",
        "1. Données et traitement\n",
        "2. Classifier SGD\n",
        "3. Arbres de décision\n",
        "4. Forêts aléatoires (Random Forests)\n",
        "5. Evaluation : métriques\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c45b358a",
      "metadata": {
        "id": "c45b358a"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "L'objectif de ce TD est de comprendre la différence entre Régression et Classification au travers de divers exemples. Dans ce TD, nous allons apprendre à importer, prétraiter et manipuler les données utilisées pour l'entrainement des modèles d'IA.\n",
        "On va voir les bonnes pratiques à effectuer pour l'entrainement des algos, la façon dont les données doivent être découpées et quelques exemples différents d'algos. Enfin, on abordera la façon d'évaluer ces modèles au moyen de métriques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0704a44",
      "metadata": {
        "id": "a0704a44"
      },
      "source": [
        "# I. Régression\n",
        "## 1. Données et traitement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84b9fbda",
      "metadata": {
        "id": "84b9fbda"
      },
      "source": [
        "Nous allons importer un jeu de données stocké sous la forme d'un fichier CSV (Comma-separated values). Ce dataset a été généré par l'IA, c'est donc un ensemble de données synthétiques. Ces données représentent un groupe d'étudiants se caractérisant par un ID unique, le nombre d'heures d'études, leur taux de présence aux cours, une note à un projet, et une note à un examen final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75af99e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "d75af99e",
        "outputId": "1bea7580-85cc-48a8-e698-4cfcf29b712f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Nom du dataset, doit être dans le même doossier que le Notebook du TD\n",
        "file_path = 'datasets/student_performance.csv'\n",
        "\n",
        "# Lecture du fichier csv et affectation dans un pandas dataframe\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Affichage des premières lignes du jeu de données pour visualiser sa structure\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44ca07a7",
      "metadata": {
        "id": "44ca07a7"
      },
      "source": [
        "Une fois notre jeu de données importé dans un dataframe, nous avons visualisé quelques échantillons avec la fonction head(). On peut aussi visualiser ces données sous la forme d'un plot. Ici, on affiche le nombre d'heures d'études en fonction de la note à l'éxamen en ordonnée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fb8576a",
      "metadata": {
        "id": "0fb8576a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['StudyHours'], df['ExamScores'], alpha=0.5)\n",
        "plt.title(\"Relation entre les heures d'étude et les scores d'examen\")\n",
        "plt.xlabel(\"Heures d'étude\")\n",
        "plt.ylabel(\"Scores d'examen\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c79220b2",
      "metadata": {
        "id": "c79220b2"
      },
      "source": [
        "# Question : Que remarquez vous sur le plot ci dessus ? Peut-on, à l'aide d'une régression, prédire la note obtenue à l'examen à partir du nombre d'heures d'étude d'un étudiant ?\n",
        "Réponse :  Il n'y a pas de corrélation directe entre le nombre d'heures d'étude et la note\n",
        "obtenue à l'éxamen, il est donc inutile ici d'entrainer un algo d'IA. Il est crucial d'analyser les\n",
        "données avant de se lancer dans la construction d'un algo d'IA."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4a73e8b",
      "metadata": {
        "id": "d4a73e8b"
      },
      "source": [
        "# Exercice 1 : Affichez un plot du taux de présence en fonction de la note à l'examen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904a20d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "904a20d0",
        "outputId": "c650e545-88ce-4231-b7fc-0e9c0dfac517"
      },
      "outputs": [],
      "source": [
        "# à compléter\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['AttendanceRate'], df['ExamScores'], alpha=0.5)\n",
        "plt.title(\"Relation entre les présences et les scores d'examen\")\n",
        "plt.xlabel(\"taux de présence\")\n",
        "plt.ylabel(\"Scores d'examen\")\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4f714ef",
      "metadata": {
        "id": "c4f714ef"
      },
      "source": [
        "# Question : Même question\n",
        "Réponse : On peut un peu ici imaginer en plissant les yeux une relation plus claire que la précédente mais ça reste très mauvais."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab04f06c",
      "metadata": {
        "id": "ab04f06c"
      },
      "source": [
        "Prenons maintenant un meilleur jeu de données :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69aa5942",
      "metadata": {
        "id": "69aa5942"
      },
      "outputs": [],
      "source": [
        "file_path_c = 'datasets/student_performance_correlated.csv'\n",
        "\n",
        "# Lecture du fichier csv et affectation dans un pandas dataframe\n",
        "dfc = pd.read_csv(file_path_c)\n",
        "\n",
        "# Affichage des première ligne du jeu de données pour visualiser sa structure\n",
        "dfc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1484f8a3",
      "metadata": {
        "id": "1484f8a3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(dfc['StudyHours'], dfc['ExamScores'], alpha=0.5)\n",
        "plt.title(\"Relation entre les heures d'étude et les scores d'examen\")\n",
        "plt.xlabel(\"Heures d'étude\")\n",
        "plt.ylabel(\"Scores d'examen\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c43ab62",
      "metadata": {
        "id": "9c43ab62"
      },
      "source": [
        "# Question : Que remarquez vous ici ? Voyez vous une correlation entre le nombre d'heures d'études et les notes à l'examen ? estimez la droite correspondante"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0c7db4",
      "metadata": {
        "id": "4a0c7db4"
      },
      "source": [
        "# Exercice 2 : faites la même chose pour le taux de présence et la note à l'examen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59546d3b",
      "metadata": {
        "id": "59546d3b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(dfc['AttendanceRate'], dfc['ExamScores'], alpha=0.5)\n",
        "plt.title(\"Relation entre les heures d'étude et les scores d'examen\")\n",
        "plt.xlabel(\"Taux de présence\")\n",
        "plt.ylabel(\"Scores d'examen\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26b0eb46",
      "metadata": {
        "id": "26b0eb46"
      },
      "source": [
        "Conclusion :\n",
        "\n",
        "Les données doivent être analysées avant utilisation, parfois prétraitées (partie NN)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7c66126",
      "metadata": {
        "id": "d7c66126"
      },
      "source": [
        "## Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785357ed",
      "metadata": {
        "id": "785357ed"
      },
      "outputs": [],
      "source": [
        "# Import des bibliothèques utiles\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8603dc70",
      "metadata": {
        "id": "8603dc70"
      },
      "source": [
        "à partir du jeu de données précédent (student_performance_correlated), nous allons réaliser une régression linéaire pour pouvoir prédire la note d'un étudiant en fonction du nombre d'heures étudiés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6700d0c0",
      "metadata": {
        "id": "6700d0c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Notre X sera la variable qu'on possède et qui servira à prédire y, ici on a le nombre d'heures\n",
        "X = dfc['StudyHours']\n",
        "# y correspond à la note de l'examen, ici donnée par la dataset mais qui sera prédite par notre régresseur linéaire sur des nouvelles données\n",
        "y = dfc['ExamScores']\n",
        "\n",
        "\n",
        "\n",
        "print(X)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d34999",
      "metadata": {
        "id": "75d34999"
      },
      "source": [
        "Visualisation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428e78b9",
      "metadata": {
        "id": "428e78b9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, s=50)\n",
        "plt.xlabel(\"Heures d'étude : StudyHours (X)\")\n",
        "plt.ylabel(\"Scores d'examen : ExamScores (y)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11eafadd",
      "metadata": {
        "id": "11eafadd"
      },
      "source": [
        "Lorsqu'on utilise les méthodes de Machine Learning, on sépare les données pour l'entrainement et une partie pour les tests. Gnénéralement on consacre entre 70 et 80% des données pour l'apprentissage et entre 30 et 20% pour les tests. La methode train_test_split permet ce découpage. La variable `test_size` permet de spécifier le pourcentage du jeu de données qui sera dans le jeu de test. On choisira par exemple `test_size` égal à 0,30. On représentera de couleurs différentes les données de test et les données d'entrainement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45612bf",
      "metadata": {
        "id": "f45612bf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Découpage des données en 2 : apprentissage et test.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Visualisation du jeu de données\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train, y_train, s=50, edgecolors='blue', label=\"Exemples d'entraînement\")\n",
        "plt.scatter(X_test, y_test, c='none', s=50, edgecolors='red', label=\"Exemples d'évaluation\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Heures d'étude : StudyHours (X)\")\n",
        "plt.ylabel(\"Scores d'examen : ExamScores (y)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb03483",
      "metadata": {
        "id": "5cb03483"
      },
      "source": [
        "On peut voir la séparation entre données d'entrainement et données de test, visualisons cela avec un tableau :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f09bd1d0",
      "metadata": {
        "id": "f09bd1d0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Créer un DataFrame pour afficher les divisions avec des couleurs\n",
        "train_data = pd.DataFrame(X_train, columns=['StudyHours'])\n",
        "train_data['ExamScores'] = y_train\n",
        "#train_data['Student'] = train_data.index\n",
        "train_data['Set'] = 'Train'\n",
        "\n",
        "test_data = pd.DataFrame(X_test, columns=['StudyHours'])\n",
        "test_data['ExamScores'] = y_test\n",
        "#test_data['Student'] = test_data.index\n",
        "test_data['Set'] = 'Test'\n",
        "\n",
        "# Combiner les données d'entraînement et de test pour la visualisation\n",
        "combined_data = pd.concat([train_data, test_data])\n",
        "\n",
        "# Ajouter un titre à la première colonne\n",
        "combined_data.index.name = 'Student'\n",
        "\n",
        "# Afficher le tableau avec des couleurs pour X et y et le numéro de l'étudiant en bleu pour train et rouge pour test\n",
        "def highlight_columns(x):\n",
        "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
        "    df1.loc[:, ['StudyHours']] = 'background-color: yellow'\n",
        "    df1.loc[:, ['ExamScores']] = 'background-color: lightblue'\n",
        "    df1.loc[x['Set'] == 'Train', ['Set']] = 'color: blue'\n",
        "    df1.loc[x['Set'] == 'Test', ['Set']] = 'color: red'\n",
        "    return df1\n",
        "\n",
        "combined_data.style.apply(highlight_columns, axis=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9b64956",
      "metadata": {
        "id": "c9b64956"
      },
      "source": [
        "## 2. Régression linéaire\n",
        "### 2.1 Régression linéaire 1d"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8588187",
      "metadata": {
        "id": "a8588187"
      },
      "source": [
        "Réalisons une régréssion linéaire sur une seule variable (donc à une dimension). Cela consiste à tracer une droite (et donc déterminer les coéfficients associés).\n",
        "\n",
        "Quelle que soit la méthode choisie, les étapes seront les mêmes :\n",
        "*   `fit()` : permet l'entrainement avec la méthode choisie\n",
        "*   `predict()` ou `transform()` : permet d'appliquer le modèle entrainé à de nouvelles données\n",
        "* `score()` permet d'évaluer le modèle sur un jeu de tests\n",
        "Nous allons appliquer une régression linéaire sur nos données d'entrainement\n",
        "\n",
        "Nous allons utiliser un méthode de regression linéaire. Il est donc necessaire d'importer les modèles linéaire (`linear_model`) de sklearn et d'utiliser la méthode `LinearRegression` de regression linéaire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23a4932",
      "metadata": {
        "id": "c23a4932"
      },
      "outputs": [],
      "source": [
        "# on commence par réimporter nos données\n",
        "\n",
        "# ATTENTION : X doit être sous cette forme, car habituellement il comporter plusieurs \"features/colonnes/caractéristiques\"\n",
        "X = dfc[['StudyHours']]\n",
        "y = dfc['ExamScores']\n",
        "\n",
        "# Découpage des données en 2 : apprentissage et test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785b65d3",
      "metadata": {
        "id": "785b65d3"
      },
      "outputs": [],
      "source": [
        "# importation du linear_model de sklearn\n",
        "from sklearn import linear_model\n",
        "\n",
        "# définition de notre régresseur linéaire que l'on appelera reg\n",
        "reg = linear_model.LinearRegression()\n",
        "\n",
        "# entrainement du modèle: détermination des paramètres de la régression linéaire, ici on lui donne X_train et y_train : données d'entrainement\n",
        "reg.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cebbc61",
      "metadata": {
        "id": "8cebbc61"
      },
      "source": [
        "Nous pouvons maintenant évaluer le modèle obtenu sur nos données d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f271c89c",
      "metadata": {
        "id": "f271c89c"
      },
      "outputs": [],
      "source": [
        "# attention, score() ici ne renvoie pas l'erreur mais la valeur du coefficient de détermination R² !\n",
        "coeff_train = reg.score(X_train, y_train)\n",
        "print(f\"Coefficient de détermination R² en train : {coeff_train:.2f}\")\n",
        "#reg.predict?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ee3fe74",
      "metadata": {
        "id": "6ee3fe74"
      },
      "source": [
        "Le coefficient de determination (R<sup>2</sup>, soit le carré du coefficient de correlation linéaire r) est un indicateur qui permet de mesurer l'adéquation entre le modèle et les données). Plus R<sup>2</sup> tend vers 1 plus les données sont proches du modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60511591",
      "metadata": {
        "id": "60511591"
      },
      "source": [
        "# Exercice 3 : Calculer ce même coefficient sur les données de tests. que constatez-vous ? pourquoi ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb911d3",
      "metadata": {
        "id": "7bb911d3"
      },
      "outputs": [],
      "source": [
        "# à compléter\n",
        "coeff_test = reg.score(X_test, y_test)\n",
        "print(f\"Coefficient de détermination R² en test : {coeff_test:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa57590",
      "metadata": {
        "id": "4aa57590"
      },
      "source": [
        "Réponse: Le coefficient est plus élevé, parce qu'il y a moins de données. On aurait pu s'attendre au contraire, puisque le modèle s'est entrainé sur les données de train."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2cccb68",
      "metadata": {
        "id": "f2cccb68"
      },
      "source": [
        "Visualisons les données d'entrainement , les données de tests et la droite de regressions linéaire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f81b15",
      "metadata": {
        "id": "f5f81b15"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train,y_train, s=50, edgecolors='blue', label=\"Exemples d'apprentissage\")\n",
        "plt.scatter(X_test,y_test, c='none', s=50, edgecolors='red', label=\"Exemples d'évaluation\")\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"\")\n",
        "\n",
        "x_min, x_max = plt.xlim()\n",
        "nx = 100\n",
        "xx = np.linspace(x_min, x_max, nx).reshape(-1,1)\n",
        "plt.plot(xx,reg.predict(xx), color='k', label=\"Régression linéaire\")\n",
        "plt.title(\"Régression linéaire unidimensionnelle\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3bd8782",
      "metadata": {
        "id": "c3bd8782"
      },
      "source": [
        "Calculons l'erreur quadratique moyenne (`mean_square_error` sur les données d'apprentissage puis sur les données de tests). Plus le MSE est faible plus les prédictions sont meilleures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09ff9b1a",
      "metadata": {
        "id": "09ff9b1a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred_train = reg.predict(X_train)\n",
        "y_pred_test = reg.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "\n",
        "print(f\"MSE = {mse_train:.3f} (train)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f695597",
      "metadata": {
        "id": "3f695597"
      },
      "source": [
        "# Exercice 4 : Calculer l'erreur quadratique moyenne pour le jeu de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25d4b14",
      "metadata": {
        "id": "e25d4b14"
      },
      "outputs": [],
      "source": [
        "#à compléter\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "print(f\"MSE = {mse_test:.3f} (test)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15502e03",
      "metadata": {
        "id": "15502e03"
      },
      "source": [
        "### 2.2 Régression linéaire multivariable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8330a39",
      "metadata": {
        "id": "f8330a39"
      },
      "source": [
        "Cette fois, au lieu de prédire le score d'examen uniquement à partir des heures d'étude, on va prendre également le taux de présence dans notre X : studyHours et AttendanceRate pour prédire le ExamScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9603e182",
      "metadata": {
        "id": "9603e182"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "# Définir les caractéristiques (X) et la cible (y)\n",
        "X = dfc[['StudyHours', 'AttendanceRate']]\n",
        "y = dfc['ExamScores']\n",
        "\n",
        "# Découpage des données en 2 : apprentissage et test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Graphique 3D : AttendanceRate en X, StudyHours en Y, et ExamScores en Z\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X_train['AttendanceRate'], X_train['StudyHours'], y_train, c='blue', label=\"Exemples d'entraînement\")\n",
        "ax.scatter(X_test['AttendanceRate'], X_test['StudyHours'], y_test, c='red', label=\"Exemples d'évaluation\")\n",
        "ax.set_xlabel(\"Taux de présence\")\n",
        "ax.set_ylabel(\"Heures d'étude\")\n",
        "ax.set_zlabel(\"Scores d'examen\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d62600e",
      "metadata": {
        "id": "5d62600e"
      },
      "source": [
        "Comme précédemment on visualise nos données, ici en 3d car on à 3 variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81662977",
      "metadata": {
        "id": "81662977"
      },
      "outputs": [],
      "source": [
        "# on commence par réimporter nos données\n",
        "\n",
        "# ATTENTION : X doit être sous cette forme, car habituellement il comporter plusieurs \"features/colonnes/caractéristiques\"\n",
        "X = dfc[['StudyHours', 'AttendanceRate']]\n",
        "y = dfc['ExamScores']\n",
        "\n",
        "# Découpage des données en 2 : apprentissage et test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e4f5d1",
      "metadata": {
        "id": "d4e4f5d1"
      },
      "source": [
        "Maintenant qu'on a nos données, on peut, comme précédemment définir puis entrainer notre régresseur linéaire :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a11d35dc",
      "metadata": {
        "id": "a11d35dc"
      },
      "outputs": [],
      "source": [
        "# définition de notre régresseur linéaire que l'on appelera reg\n",
        "reg2 = linear_model.LinearRegression()\n",
        "\n",
        "# entrainement du modèle: détermination des paramètres de la régression linéaire\n",
        "reg2.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9033abe",
      "metadata": {
        "id": "f9033abe"
      },
      "outputs": [],
      "source": [
        "# Prédire avec l'ensemble d'entraînement pour tracer la droite de régression\n",
        "y_train_pred = reg2.predict(X_train)\n",
        "\n",
        "\n",
        "# Graphique 3D : AttendanceRate en X, StudyHours en Y, et ExamScores en Z\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X_train['AttendanceRate'], X_train['StudyHours'], y_train, c='blue', label=\"Exemples d'entraînement\")\n",
        "ax.scatter(X_test['AttendanceRate'], X_test['StudyHours'], y_test, c='red', label=\"Exemples d'évaluation\")\n",
        "\n",
        "# Tracer la droite de régression\n",
        "ax.plot_trisurf(X_train['AttendanceRate'], X_train['StudyHours'], y_train_pred, color='green', alpha=0.5)\n",
        "\n",
        "ax.set_xlabel(\"Taux de présence\")\n",
        "ax.set_ylabel(\"Heures d'étude\")\n",
        "ax.set_zlabel(\"Scores d'examen\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76476741",
      "metadata": {
        "id": "76476741"
      },
      "source": [
        "## 3. Regression polynomiale\n",
        "\n",
        "\n",
        "On utilise la régression polynomiale lorsque les relations entre les variables sont non linéaires. Cela permet de modéliser des courbes plus complexes et d’améliorer la précision des prédictions.\n",
        "Elle offre généralement une plus grande flexibilité pour capturer des tendances changeantes, mais il faut se méfier du surapprentissage avec un degré de polynome trop élevé.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5200a5c",
      "metadata": {
        "id": "d5200a5c"
      },
      "source": [
        "On va commencer par générer des données aléatoires polynomiales, car nos jeux de données précédents présentaient une tendance linéaire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c2d45a4",
      "metadata": {
        "id": "9c2d45a4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Seed\n",
        "np.random.seed(42)\n",
        "\n",
        "# On génère des données polynomiales aléatoires pour l'exemple,\n",
        "# on ne prend plus notre jeu de donnée préféré avec les students\n",
        "n_samples = 100\n",
        "X = np.linspace(-10, 10, n_samples).reshape(-1, 1)\n",
        "y = 0.5 * X**2 + 2 * X + 3 + np.random.normal(0, 5, n_samples).reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Split train test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78845a4c",
      "metadata": {
        "id": "78845a4c"
      },
      "source": [
        "Une fois nos données générées et séparées, on peut entrainer le régresseur polynomial. Contrairement au régresseur linéaire, une étape supplémentaire doit être effectuée :  l'entrainement et la transformation en Features Polynomiales des X."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e18eef6a",
      "metadata": {
        "id": "e18eef6a"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Sur Sklearn, pour créer un régresseur polynomial, on doit passer par le PolynomialFeatures\n",
        "#qui va convertir les données en données polynomiales\n",
        "#noter le degrée qui correspondra au degrée de notre régrésseur polynomial par la suite\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "\n",
        "\n",
        "#on transforme donc notre X_train et X_test avec le PolynomialFeatures\n",
        "X_poly_train = poly.fit_transform(X_train)\n",
        "X_poly_test = poly.transform(X_test)\n",
        "\n",
        "# On créé et entraine notre régresseur polynomial\n",
        "poly_regressor = LinearRegression()\n",
        "poly_regressor.fit(X_poly_train, y_train)\n",
        "\n",
        "# Prédiction\n",
        "y_poly_pred = poly_regressor.predict(X_poly_test)\n",
        "\n",
        "# Plot des données polynomiales en bleu, et des prédictions en jaune\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', label=\"Données réelles\")\n",
        "plt.scatter(X_test, y_poly_pred, color='yellow', label=\"Prédictions\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Régression polynomiale\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0fdac9e",
      "metadata": {
        "id": "b0fdac9e"
      },
      "source": [
        "Ici on peut visualiser en bleu les données polynomiales générées aléatoirement et en jaune les données prédites par le régresseur polynomial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535691a1",
      "metadata": {
        "id": "535691a1"
      },
      "source": [
        "Le code ci-dessous permet de générer des données polynomiales suivant un degré aléatoire (entre 2 et 8), puis on définit une fonction plot_polynomial_regression(degree) qui permet d'entrainer un regresseur polynomial de degré donné en paramètre et d'afficher les prédictions sur un plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c9a383",
      "metadata": {
        "id": "d0c9a383"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Seed, vous pouvez la faire varier pour avoir un jeux de données avec un degrée différent\n",
        "np.random.seed(7)\n",
        "\n",
        "# Generation d'un jeu de données polynomiales avec des valeurs aléatoires\n",
        "degree = np.random.randint(2, 8)\n",
        "n_samples = 100\n",
        "X = np.linspace(-10, 10, n_samples).reshape(-1, 1)\n",
        "coefficients = np.random.randn(degree + 1)\n",
        "y = sum(coefficients[i] * X**i for i in range(degree + 1)) + np.random.normal(0, 5, n_samples).reshape(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "# Split train test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "\n",
        "#fonction qui permet l'affichage des prédictions et des données réelles avec en entrée le degré du polynome\n",
        "def plot_polynomial_regression(degree):\n",
        "    # transformation des doonnées avec degré\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    # entrainement du polynoomial feature\n",
        "    X_poly_train = poly.fit_transform(X_train)\n",
        "    # application du polynomial feature sur le jeu de test\n",
        "    X_poly_test = poly.transform(X_test)\n",
        "\n",
        "    # creation et entrainement du regresseur\n",
        "    poly_regressor = LinearRegression()\n",
        "    poly_regressor.fit(X_poly_train, y_train)\n",
        "\n",
        "    # prédiction\n",
        "    y_poly_pred = poly_regressor.predict(X_poly_test)\n",
        "\n",
        "    # visualisation\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(X, y, color='blue', label=\"Données réelles\")\n",
        "    plt.scatter(X_test, y_poly_pred, color='yellow', label=\"Prédictions\")\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.title(f\"Régression polynomiale (degré {degree})\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45cd46f2",
      "metadata": {
        "id": "45cd46f2"
      },
      "source": [
        "# Exercice 5: Trouver le bon degré du régresseur polynomial en utilisant la fonction ci-dessus\n",
        "\n",
        "\n",
        "## Question bonus : automatisez la recherche de degrée à l'aide de métrique style r2 ou mse vues précédemment\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a362da",
      "metadata": {
        "id": "97a362da"
      },
      "outputs": [],
      "source": [
        "# à compléter\n",
        "# Utiliser plot_polynomial_regression et trouver le bon degré du polynome\n",
        "\n",
        "plot_polynomial_regression(degree=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "620d3294",
      "metadata": {
        "id": "620d3294"
      },
      "source": [
        "# II. Classification\n",
        "## 1. Données et traitement\n",
        "2. SGD\n",
        "3. Arbres de décision\n",
        "4. Forêts aléatoires (Random Forests)\n",
        "5. Evaluation : métriques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3534b007",
      "metadata": {
        "id": "3534b007"
      },
      "source": [
        "### Dataset MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76a690bf",
      "metadata": {
        "id": "76a690bf"
      },
      "source": [
        "Dans ce chapitre, nous utiliserons l'ensemble de données MNIST, qui est un ensemble de 70 000 petites images de chiffres écrits à la main par des lycéens et des employés du Bureau du recensement des États-Unis. Chaque image est étiquetée avec le chiffre qu'elle représente. Cet ensemble de données a été tellement étudié qu'il est souvent appelé le \"Hello World\" de l'apprentissage automatique : chaque fois que des personnes inventent un nouvel algorithme de classification, elles sont curieuses de voir comment il se comportera sur MNIST. Tôt ou tard, toute personne apprenant l'apprentissage automatique se penche sur MNIST. Scikit-Learn fournit de nombreuses fonctions d'aide pour télécharger des ensembles de données populaires. MNIST en fait partie. Le code suivant récupère l'ensemble de données MNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c17305",
      "metadata": {
        "id": "b4c17305"
      },
      "outputs": [],
      "source": [
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f83eb38e",
      "metadata": {
        "id": "f83eb38e"
      },
      "source": [
        "On importe le jeu de données MNIST, ici sous la forme d'un fichier .mat, on peut aussi le récupérer via le code en commentaire, directement sur internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea5bb5e",
      "metadata": {
        "id": "3ea5bb5e"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from scipy.io import loadmat\n",
        "\n",
        "\n",
        "#mnist = fetch_openml('mnist_784', as_frame=False)\n",
        "\n",
        "mnist = loadmat(\"datasets/mnist-original.mat\")\n",
        "mnist_data = mnist[\"data\"].T\n",
        "mnist_label = mnist[\"label\"][0]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb18e74",
      "metadata": {
        "id": "eeb18e74"
      },
      "outputs": [],
      "source": [
        "# affichage des clefs\n",
        "mnist.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac02a8eb",
      "metadata": {
        "id": "ac02a8eb"
      },
      "source": [
        "Les ensembles de données chargés par Scikit-Learn ont généralement une structure de dictionnaire similaire comprenant :\n",
        "• Une clé DESCR décrivant l'ensemble de données\n",
        "• Une clé data contenant un tableau avec une ligne par instance et une colonne par caractéristique\n",
        "• Une clé target contenant un tableau avec les étiquettes.  \n",
        "\n",
        "Ici, puisque nous importons le dataset depuis une source externe, on retrouve une structure similaire, mais target est label dans notre cas.\n",
        "\n",
        "Affichons ces tableaux :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd4d202",
      "metadata": {
        "id": "afd4d202"
      },
      "outputs": [],
      "source": [
        "X, y = mnist_data, mnist_label\n",
        "\n",
        "#print(mnist.categories)\n",
        "print('data',X[0:100])\n",
        "print('target', y[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86670ca1",
      "metadata": {
        "id": "86670ca1"
      },
      "source": [
        "Chaque instance (70000 instances), ou échantillon est une image de 28x28."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bbf7ed8",
      "metadata": {
        "id": "6bbf7ed8"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f9eb881",
      "metadata": {
        "id": "5f9eb881"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b239663",
      "metadata": {
        "id": "9b239663"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5ce063",
      "metadata": {
        "id": "3a5ce063"
      },
      "source": [
        "Il y a 70 000 images, et chaque image a 784 caractéristiques. Cela est dû au fait que chaque image mesure 28x28 pixels, et chaque caractéristique représente simplement l'intensité d'un pixel, de 0 (blanc) à 255 (noir). Affichons un échantillon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c59b7c",
      "metadata": {
        "id": "b4c59b7c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_digit(image_data):\n",
        "    image = image_data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "some_digit = X[0]\n",
        "plot_digit(some_digit)\n",
        "#save_fig(\"some_digit_plot\")  # extra code\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f1fd34f",
      "metadata": {
        "id": "8f1fd34f"
      },
      "source": [
        "Cela ressemble à un 0, et effectivement le label le confirme :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c9b06e",
      "metadata": {
        "id": "37c9b06e"
      },
      "outputs": [],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afbdb5d1",
      "metadata": {
        "id": "afbdb5d1"
      },
      "source": [
        "Affichage d'exemples d'images disponibles dans le dataset :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bdf42b",
      "metadata": {
        "id": "37bdf42b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(9, 9))\n",
        "for idx, image_data in enumerate(X[:100]):\n",
        "    plt.subplot(10, 10, idx + 1)\n",
        "    plot_digit(image_data)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "#save_fig(\"more_digits_plot\", tight_layout=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da678eef",
      "metadata": {
        "id": "da678eef"
      },
      "source": [
        "Découpage de notre jeu de données en prenant 80% pour l'entrainement et 20% pour le test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81d42753",
      "metadata": {
        "id": "81d42753"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(y)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19d8dac0",
      "metadata": {
        "id": "19d8dac0"
      },
      "source": [
        "L'ensemble d'entraînement est mélangé par la fonction split, ce qui est une bonne chose car cela garantit que toutes les partitions de validation croisée seront similaires (vous ne voulez pas qu'une partition manque certains chiffres). De plus, certains algorithmes d'apprentissage sont sensibles à l'ordre des instances d'entraînement, et ils se comportent mal s'ils reçoivent de nombreuses instances similaires à la suite. Mélanger l'ensemble de données garantit que cela ne se produira pas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0f7d406",
      "metadata": {
        "id": "a0f7d406"
      },
      "source": [
        " 1. Données et traitement\n",
        "## 2. SGD\n",
        "3. Arbres de décision\n",
        "4. Forêts aléatoires (Random Forests)\n",
        "5. Evaluation : métriques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1ed39c",
      "metadata": {
        "id": "2c1ed39c"
      },
      "source": [
        "### Entrainement d'un classifier binaire SGD\n",
        "Simplifions le problème pour l'instant et essayons seulement d'identifier un chiffre, par exemple le chiffre 5. Ce \"détecteur de 5\" sera un exemple de classifieur binaire, capable de distinguer uniquement deux classes, 5 et non-5. Créons les vecteurs cibles pour cette tâche de classification :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64c35aa",
      "metadata": {
        "id": "c64c35aa"
      },
      "outputs": [],
      "source": [
        "# petite subtilité, on créé un sous ensemble de y poour avoir une classification binaire\n",
        "# donc au lieu d'avoir y qui contient 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, y_5 contient True ou False, True si le y valait 5, et False sinon, on créé un problème binaire plus facile à classifier\n",
        "\n",
        "y_train_5 = [True if value == 5 else False for value in y_train]\n",
        "y_test_5 = [True if value == 5 else False for value in y_test]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac191b6b",
      "metadata": {
        "id": "ac191b6b"
      },
      "source": [
        "Maintenant choisissons un classifieur et entraînons-le. Un bon point de départ est d'utiliser un classifieur de descente de gradient stochastique (SGD) en utilisant la classe SGDClassifier de Scikit-Learn. Ce classifieur présente l'avantage d'être capable de gérer efficacement des ensembles de données très volumineux. Cela est en partie dû au fait que SGD traite les instances d'entraînement indépendamment, une par une (ce qui rend également SGD bien adapté à l'apprentissage en ligne). Créons un SGDClassifier et entraînons-le sur l'ensemble d'entraînement complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9c2ebe",
      "metadata": {
        "id": "5c9c2ebe"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "\n",
        "sgd_clf.fit(X_train, y_train_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e6e08c",
      "metadata": {
        "id": "c7e6e08c"
      },
      "source": [
        "Maintenant on peut l'utiliser pour détecter les images contenant le nombre 5 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828b32ba",
      "metadata": {
        "id": "828b32ba"
      },
      "outputs": [],
      "source": [
        "y_pred = sgd_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f0ed576",
      "metadata": {
        "id": "2f0ed576"
      },
      "source": [
        "y_pred correspond aux données prédites par notre classifieur SGD. On comparera les y_pred aux y_test_5 par la suite."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0042fd0",
      "metadata": {
        "id": "f0042fd0"
      },
      "source": [
        "### Métriques\n",
        "#### Mesures de performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "304aea81",
      "metadata": {
        "id": "304aea81"
      },
      "source": [
        "#### Mesure de l'accuracy\n",
        "Pour évaluer notre classifieur, on peut utiliser l'accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f916db6",
      "metadata": {
        "id": "0f916db6"
      },
      "outputs": [],
      "source": [
        "# On importe la mesure de l'accuracy avec sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# calcul de l'accuracy par rapport aux y prédites par notre classifieur, et les y_test_5\n",
        "accuracy = accuracy_score(y_test_5, y_pred)\n",
        "print(\"Accuracy SGD :\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9204cdeb",
      "metadata": {
        "id": "9204cdeb"
      },
      "source": [
        "Comparaison de l'accuracy du classifieur SGD avec un classifier \"dumb\" :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ddd55b6",
      "metadata": {
        "id": "0ddd55b6"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier()\n",
        "dummy_clf.fit(X_train, y_train_5)\n",
        "y_pred_dumb = dummy_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "665fc98e",
      "metadata": {
        "id": "665fc98e"
      },
      "source": [
        "Afficher l'accuracy de ce classifieur Dummy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a284f187",
      "metadata": {
        "id": "a284f187"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy = accuracy_score(y_test_5, y_pred_dumb)\n",
        "print(\"Accuracy Dummy :\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f78315",
      "metadata": {
        "id": "28f78315"
      },
      "source": [
        "On remarque ici que l'accuracy de notre classifieur SGB est bien meilleure que celle du classifieur Dummy. Néanmoins, l'accuracy du Dummy reste très élevée, ce qui implique que la mesure de l'accuracy n'est pas forcément la meilleure façon d'évaluer un classifieur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5862e0fd",
      "metadata": {
        "id": "5862e0fd"
      },
      "source": [
        "#### Matrices de Confusion\n",
        "Une bien meilleure façon d'évaluer les performances d'un classifieur est d'examiner la matrice de confusion. L'idée générale est de compter le nombre de fois où des instances de la classe A sont classées comme la classe B. Par exemple, pour connaître le nombre de fois où le classifieur a confondu des images de 5 avec des 3, vous regarderiez dans la 5e ligne et la 3e colonne de la matrice de confusion. Pour calculer la matrice de confusion, vous avez d'abord besoin d'un ensemble de prédictions, afin de pouvoir les comparer aux cibles réelles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f82dae",
      "metadata": {
        "id": "f8f82dae"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "\n",
        "# création de la matrice de confusion sur le jeu de test\n",
        "cm = confusion_matrix(y_test_5, y_pred)\n",
        "cm\n",
        "\n",
        "# affichage\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dummy_clf.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9cd96a1",
      "metadata": {
        "id": "e9cd96a1"
      },
      "source": [
        "Chaque ligne d'une matrice de confusion représente une classe réelle, tandis que chaque colonne représente une classe prédite. La première ligne de cette matrice concerne les images non-5 (la classe négative) : 12499 d'entre elles ont été correctement classées comme non-5 (on les appelle les vrais négatifs), tandis que les 215 restantes ont été incorrectement classées comme des 5 (faux positifs). La deuxième ligne concerne les images de 5 (la classe positive) : 240 ont été incorrectement classées comme des non-5 (faux négatifs), tandis que les 1046 restantes ont été correctement classées comme des 5 (vrais positifs). Un classifieur parfait aurait uniquement des vrais positifs et des vrais négatifs, donc sa matrice de confusion ne présenterait que des valeurs non nulles sur sa diagonale principale (du coin supérieur gauche au coin inférieur droit)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "329e5c6e",
      "metadata": {
        "id": "329e5c6e"
      },
      "source": [
        "# Exercice 6 : Trouver la matrice de confusion idéale, celle obtenue si les prédictions sont parfaites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70ae32c9",
      "metadata": {
        "id": "70ae32c9"
      },
      "outputs": [],
      "source": [
        "# à compléter\n",
        "y_test_perfect_predictions = y_test_5  # pretend we reached perfection\n",
        "\n",
        "cm = confusion_matrix(y_test_5, y_test_perfect_predictions)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dummy_clf.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2279d812",
      "metadata": {
        "id": "2279d812"
      },
      "source": [
        "#### Precision et Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a3d930e",
      "metadata": {
        "id": "5a3d930e"
      },
      "source": [
        "La matrice de confusion vous donne beaucoup d'informations, mais parfois vous pouvez préférer une mesure plus concise. Une mesure intéressante à examiner est l'exactitude des prédictions positives ; cela s'appelle la précision du classifieur (ou prédiction positive).\n",
        "\n",
        "La précision d'un classifieur est une mesure qui évalue la proportion de prédictions positives qui sont effectivement correctes. Elle est calculée en divisant le nombre de vrais positifs par la somme des vrais positifs et des faux positifs. En d'autres termes, elle représente la capacité du classifieur à ne pas identifier à tort des échantillons négatifs comme positifs.\n",
        "\n",
        "La précision est particulièrement utile dans les cas où les faux positifs sont coûteux ou indésirables. Par exemple, dans un système de détection de spam, il est important de minimiser le nombre de courriels légitimes classés comme spams.\n",
        "\n",
        "Pour calculer la précision à partir de la matrice de confusion, vous pouvez utiliser la formule suivante :\n",
        "\n",
        "Précision = Vrais positifs / (Vrais positifs + Faux positifs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11f20331",
      "metadata": {
        "id": "11f20331"
      },
      "source": [
        "Une façon banale d'obtenir une précision parfaite est de faire une seule prédiction positive et de s'assurer qu'elle est correcte (précision = 1/1 = 100%). Cela ne serait pas très utile car le classifieur ignorerait toutes les instances positives sauf une. C'est pourquoi la précision est généralement utilisée en conjonction avec une autre mesure appelée sensibilité (Recall), également appelée sensibilité ou taux de vrais positifs.\n",
        "\n",
        "La sensibilité est une mesure qui évalue la proportion d'échantillons positifs réellement identifiés par le classifieur. Elle est calculée en divisant le nombre de vrais positifs par la somme des vrais positifs et des faux négatifs. En d'autres termes, elle représente la capacité du classifieur à détecter correctement les échantillons positifs.\n",
        "\n",
        "Le recall est particulièrement utile dans les cas où les faux négatifs sont coûteux ou indésirables. Par exemple, dans un système de détection de fraude, il est important de minimiser le nombre de transactions frauduleuses non détectées.\n",
        "\n",
        "Pour calculer le recall à partir de la matrice de confusion, vous pouvez utiliser la formule suivante :\n",
        "\n",
        "Recall = Vrais positifs / (Vrais positifs + Faux négatifs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f970cf6",
      "metadata": {
        "id": "6f970cf6"
      },
      "source": [
        "Scikit-Learn propose des fonctions pour calculer des métriques, incluant la precision et le recall :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8b3520c",
      "metadata": {
        "id": "d8b3520c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_score(y_test_5, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e160c6",
      "metadata": {
        "id": "c6e160c6"
      },
      "outputs": [],
      "source": [
        "recall_score(y_test_5, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "667b521d",
      "metadata": {
        "id": "667b521d"
      },
      "source": [
        "Maintenant, votre détecteur de 5 ne semble pas aussi performant qu'il ne l'était lorsque vous avez examiné son accuracy. Lorsqu'il affirme qu'une image représente un 5, il est correct seulement 82% du temps. De plus, il ne détecte que 81% des 5. Il est souvent pratique de combiner la précision et le recall dans une seule mesure appelée score F1, en particulier si vous avez besoin d'une manière simple de comparer deux classifieurs. Le score F1 est la moyenne harmonique de la précision et du rappel. Alors que la moyenne régulière traite toutes les valeurs de manière égale, la moyenne harmonique accorde beaucoup plus de poids aux valeurs faibles. Par conséquent, le classifieur n'obtiendra un score F1 élevé que si à la fois le recall et la précision sont élevés.\n",
        "\n",
        "F1 = 2 * (précision * recall) / (précision + recall)\n",
        "\n",
        "On peut directement appeler la fonction comme pour les métriques précédentes :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3205594e",
      "metadata": {
        "id": "3205594e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_test_5, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc83bfc",
      "metadata": {
        "id": "2cc83bfc"
      },
      "source": [
        "Le score F1 favorise les classifieurs qui ont une précision et un rappel similaires. Ce n'est pas toujours ce que vous voulez : dans certains contextes, vous vous souciez principalement de la précision, et dans d'autres, vous vous souciez vraiment du rappel. Par exemple, si vous avez formé un classifieur pour détecter des vidéos adaptées aux enfants, vous préféreriez probablement un classifieur qui rejette de nombreuses bonnes vidéos (faible rappel) mais ne conserve que celles qui sont sécurisées (haute précision), plutôt qu'un classifieur ayant un rappel beaucoup plus élevé mais laissant apparaître quelques vidéos vraiment mauvaises dans votre produit (dans de tels cas, vous voudrez peut-être même ajouter une étape manuelle pour vérifier la sélection vidéo du classifieur). D'un autre côté, supposez que vous entraîniez un classifieur pour détecter les voleurs à l'étalage sur des images de surveillance : il est probablement acceptable que votre classifieur n'ait qu'une précision de 30% tant qu'il a un rappel de 99% (bien sûr, les agents de sécurité recevront quelques fausses alertes, mais presque tous les voleurs à l'étalage seront attrapés).\n",
        "\n",
        "Malheureusement, vous ne pouvez pas avoir les deux à la fois : augmenter la précision réduit le rappel, et vice versa. Cela s'appelle le compromis précision/rappel."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7dc792e",
      "metadata": {
        "id": "e7dc792e"
      },
      "source": [
        "#### Compromis Precision/Recall\n",
        "\n",
        "Pour comprendre ce compromis, examinons comment le SGDClassifier prend ses décisions de classification. Pour chaque instance, il calcule un score basé sur une fonction de décision, et si ce score est supérieur à un seuil, il attribue l'instance à la classe positive, sinon à la classe négative. Si vous augmentez le seuil, un faux positif peut devenir  un vrai négatif, augmentant ainsi la précision, mais un vrai positif peut devenir  un faux négatif, réduisant le recall. Inversement, abaisser le seuil augmente le recall et réduit la précision. Scikit-Learn ne vous permet pas de définir le seuil directement, mais il vous donne accès aux scores de décision qu'il utilise pour faire des prédictions. Au lieu d'appeler la méthode predict() du classifieur, vous pouvez appeler sa méthode decision_function(), qui renvoie un score pour chaque instance, puis faire des prédictions basées sur ces scores en utilisant n'importe quel seuil que vous souhaitez :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ecfa235",
      "metadata": {
        "id": "8ecfa235"
      },
      "outputs": [],
      "source": [
        "y_scores = sgd_clf.decision_function([some_digit])\n",
        "y_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9b34e6",
      "metadata": {
        "id": "df9b34e6"
      },
      "outputs": [],
      "source": [
        "threshold = 0\n",
        "y_some_digit_pred = (y_scores > threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32fef366",
      "metadata": {
        "id": "32fef366"
      },
      "outputs": [],
      "source": [
        "y_some_digit_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4aa4412",
      "metadata": {
        "id": "f4aa4412"
      },
      "source": [
        "Le classifieur SGD utilise un seuil égal à 0, donc le code précédent retourne le même résultat que la fonction predict(). Augmentons le seuil :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4677f3c1",
      "metadata": {
        "id": "4677f3c1"
      },
      "outputs": [],
      "source": [
        "threshold = 3000\n",
        "y_some_digit_pred = (y_scores > threshold)\n",
        "y_some_digit_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c623dda7",
      "metadata": {
        "id": "c623dda7"
      },
      "source": [
        "Cela confirme que l'augmentation du seuil diminue le recall. L'image représente effectivement un 5, et le classifieur le détecte lorsque le seuil est à 0, mais le manque lorsque le seuil est augmenté à 8 000.\n",
        "Maintenant, comment décidez-vous du seuil à utiliser ? Pour cela, vous devrez d'abord obtenir les scores de toutes les instances dans l'ensemble d'entraînement en utilisant à nouveau la fonction cross_val_predict(), mais cette fois en précisant que vous voulez qu'elle renvoie les scores de décision au lieu des prédictions :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f370bd",
      "metadata": {
        "id": "e4f370bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "\n",
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
        "                             method=\"decision_function\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8b6515",
      "metadata": {
        "id": "2e8b6515"
      },
      "source": [
        "Maintenant, avec ces scores, vous pouvez calculer la précision et le recall pour tous les seuils possibles en utilisant la fonction precision_recall_curve() :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4052e91c",
      "metadata": {
        "id": "4052e91c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde412db",
      "metadata": {
        "id": "fde412db"
      },
      "source": [
        "Finalement, vous pouvez afficher la precision et le recall comme des fonctions de la valeur du seuil :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c310b1e9",
      "metadata": {
        "id": "c310b1e9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))  # extra code – it's not needed, just formatting\n",
        "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
        "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
        "plt.vlines(threshold, 0, 1.0, \"k\", \"dotted\", label=\"threshold\")\n",
        "\n",
        "# extra code – this section just beautifies and saves Figure 3–5\n",
        "idx = (thresholds >= threshold).argmax()  # first index ≥ threshold\n",
        "plt.plot(thresholds[idx], precisions[idx], \"bo\")\n",
        "plt.plot(thresholds[idx], recalls[idx], \"go\")\n",
        "plt.axis([-50000, 50000, 0, 1])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc=\"center right\")\n",
        "#save_fig(\"precision_recall_vs_threshold_plot\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f0f6a2",
      "metadata": {
        "id": "e1f0f6a2"
      },
      "outputs": [],
      "source": [
        "idx_for_90_precision = (precisions >= 0.90).argmax()\n",
        "threshold_for_90_precision = thresholds[idx_for_90_precision]\n",
        "threshold_for_90_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b73f97",
      "metadata": {
        "id": "b6b73f97"
      },
      "source": [
        "#### Courbe ROC\n",
        "\n",
        "La courbe de caractéristique de fonctionnement du récepteur (Receiver Operating Characteristic) est un autre outil couramment utilisé avec les classifieur binaires. Elle est très similaire à la courbe précision/rappel, mais au lieu de représenter la précision par rapport au rappel, la courbe ROC représente le taux de vrais positifs (un autre nom pour le rappel) par rapport au taux de faux positifs. Le taux de faux positifs (FPR) est le rapport d'instances négatives incorrectement classées comme positives. Il est égal à un moins le taux de vrais négatifs, qui est le rapport d'instances négatives correctement classées comme négatives. Le TNR est également appelé spécificité. Ainsi, la courbe ROC représente la sensibilité (rappel) par rapport à 1 moins la spécificité.\n",
        "Pour tracer la courbe ROC, vous devez d'abord calculer le TPR et le FPR pour diverses valeurs de seuil, en utilisant la fonction roc_curve() :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edac75a0",
      "metadata": {
        "id": "edac75a0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65d36aa8",
      "metadata": {
        "id": "65d36aa8"
      },
      "source": [
        "Affichage des FPR (False Positive Rate) en fonction des TPR (True Positive Rate):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a8b25f",
      "metadata": {
        "id": "d3a8b25f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.patches as patches\n",
        "idx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()\n",
        "tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]\n",
        "\n",
        "plt.figure(figsize=(6, 5))  # extra code – not needed, just formatting\n",
        "plt.plot(fpr, tpr, linewidth=2, label=\"ROC curve\")\n",
        "plt.plot([0, 1], [0, 1], 'k:', label=\"Random classifier's ROC curve\")\n",
        "plt.plot([fpr_90], [tpr_90], \"ko\", label=\"Threshold for 90% precision\")\n",
        "\n",
        "plt.gca().add_patch(patches.FancyArrowPatch(\n",
        "    (0.20, 0.89), (0.07, 0.70),\n",
        "    connectionstyle=\"arc3,rad=.4\",\n",
        "    arrowstyle=\"Simple, tail_width=1.5, head_width=8, head_length=10\",\n",
        "    color=\"#444444\"))\n",
        "plt.text(0.12, 0.71, \"Higher\\nthreshold\", color=\"#333333\")\n",
        "plt.xlabel('False Positive Rate (Fall-Out)')\n",
        "plt.ylabel('True Positive Rate (Recall)')\n",
        "plt.grid()\n",
        "plt.axis([0, 1, 0, 1])\n",
        "plt.legend(loc=\"lower right\", fontsize=13)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5173fd2",
      "metadata": {
        "id": "b5173fd2"
      },
      "source": [
        "Encore une fois, il y a un compromis : plus le rappel (TPR) est élevé, plus le classifieur produit de faux positifs (FPR). La ligne en pointillés représente la courbe ROC d'un classifieur purement aléatoire ; un bon classifieur reste aussi loin que possible de cette ligne (vers le coin supérieur gauche).\n",
        "Une façon de comparer les classifieurs est de mesurer la surface sous la courbe (AUC). Un classifieur parfait aura une AUC-ROC égale à 1, tandis qu'un classifieur purement aléatoire aura une AUC-ROC égale à 0,5. Scikit-Learn fournit une fonction pour calculer l'AUC-ROC :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "114f3cf1",
      "metadata": {
        "id": "114f3cf1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_train_5, y_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9e473a6",
      "metadata": {
        "id": "f9e473a6"
      },
      "source": [
        "Ici on a une aire sous la courbe de 94%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5ebba7",
      "metadata": {
        "id": "bd5ebba7"
      },
      "source": [
        "# 4.Arbres de décision"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20c6c2e4",
      "metadata": {
        "id": "20c6c2e4"
      },
      "source": [
        "Maintenant, expérimentons les arbres de décision, ci dessous un très court code illustrer le fonctionnement des DT :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b079af0",
      "metadata": {
        "id": "8b079af0"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "\n",
        "#instantiation du dt\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "#creation d'un mini dataset bidon pour l'exemple d'instantiation\n",
        "X = [[0, 0], [1, 1]]\n",
        "y = [0, 1]\n",
        "\n",
        "#entrainement du DT, attention, il faudra prendre X_train et y_train, ici mini exemple pour montrer la syntaxe\n",
        "clf = clf.fit(X, y)\n",
        "# affichage des prédictions\n",
        "clf.predict([[2., 2.]])\n",
        "#affichage des probabilités de prédiction\n",
        "clf.predict_proba([[2., 2.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b936f69",
      "metadata": {
        "id": "5b936f69"
      },
      "source": [
        "Dans cet exemple nous allons travailler avec la base iris. C'est une base classique, facilement accessible dans scikit learn. Elle permet la classification des fleurs iris en fonction de la longueur et largeur des pétales et des sépales\n",
        "\n",
        "On commence par charger le jeu de donnée dataset iris. On appelera X le vecteur correspondant au jeu de données et Y la cible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30407efa",
      "metadata": {
        "id": "30407efa"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45eb45f8",
      "metadata": {
        "id": "45eb45f8"
      },
      "source": [
        "On construit l'arbre de décision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec234e7",
      "metadata": {
        "id": "4ec234e7"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae4378e",
      "metadata": {
        "id": "8ae4378e"
      },
      "source": [
        "Visualisation de l'arbre\n",
        "\n",
        "A l'aide de la méthode plot_tree, on peut visualiser l'arbre construit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "780439c2",
      "metadata": {
        "id": "780439c2"
      },
      "outputs": [],
      "source": [
        "tree.plot_tree(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75d4f04",
      "metadata": {
        "id": "d75d4f04"
      },
      "source": [
        "Visualisation de l'arbre sous forme de texte :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f18c402",
      "metadata": {
        "id": "3f18c402"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "r = export_text(clf, feature_names=iris['feature_names'])\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8868bc0",
      "metadata": {
        "id": "b8868bc0"
      },
      "source": [
        "On peut aussi visualiser les données par paires"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3e9ae1",
      "metadata": {
        "id": "5c3e9ae1"
      },
      "source": [
        "Caractéristique de l'arbre\n",
        "\n",
        "Calculer les statistiques (moyenne et écart-type) des quatre variables : longueur de sépale, largueur de sépale, longueur de pétale et largeur de pétale.\n",
        "\n",
        "Pour cela, on utilisera la méthode describe de scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783a6509",
      "metadata": {
        "id": "783a6509"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "scipy.stats.describe(iris.data[:,:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "710b2297",
      "metadata": {
        "id": "710b2297"
      },
      "source": [
        "Combien y a-t-il d’exemples de chaque classe ? On pourra utiliser la méthode bincount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf76b6c7",
      "metadata": {
        "id": "bf76b6c7"
      },
      "outputs": [],
      "source": [
        "np.bincount(iris.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a5957d6",
      "metadata": {
        "id": "2a5957d6"
      },
      "source": [
        "Construction et exploitation du modéle\n",
        "\n",
        "Avant de construire le modèle, séparons le jeu de données en deux : 70% pour l’apprentissage, 30% pour le test."
      ]
    },
    {
      "cell_type": "raw",
      "id": "ddfd2235",
      "metadata": {
        "id": "ddfd2235"
      },
      "source": [
        "Ecrire le code correspondant pour la préparation des données (test et entrainement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0d6e1e",
      "metadata": {
        "id": "5e0d6e1e"
      },
      "outputs": [],
      "source": [
        "#A completer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "909b664c",
      "metadata": {
        "id": "909b664c"
      },
      "source": [
        "Nous pouvons désormais construire un arbre de décision sur ces données :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91ebe02f",
      "metadata": {
        "id": "91ebe02f"
      },
      "source": [
        "# Exercice 7 : Ecrire le code correspondant et effectuer l'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06305539",
      "metadata": {
        "id": "06305539"
      },
      "outputs": [],
      "source": [
        "# à compléter\n",
        "from sklearn import tree\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6832e9",
      "metadata": {
        "id": "4b6832e9"
      },
      "source": [
        "Une fois l’apprentissage terminé, nous pouvons visualiser l’arbre, soit avec matplotlib en passant par la méthode plot_tree, soit avec l’outil graphviz (commande dot). Par exemple, avec matplotlib :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f695bb64",
      "metadata": {
        "id": "f695bb64"
      },
      "outputs": [],
      "source": [
        "tree.plot_tree(clf, filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68255491",
      "metadata": {
        "id": "68255491"
      },
      "source": [
        "Prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9b6aaf",
      "metadata": {
        "id": "ef9b6aaf"
      },
      "outputs": [],
      "source": [
        "clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16b78a5d",
      "metadata": {
        "id": "16b78a5d"
      },
      "source": [
        "On peut de cette façon calculer le score en test. Comment est calculé le score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9e12d65",
      "metadata": {
        "id": "f9e12d65"
      },
      "outputs": [],
      "source": [
        "clf.score(X_test, y_test)\n",
        "clf.score?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f8fd83",
      "metadata": {
        "id": "d4f8fd83"
      },
      "source": [
        "# QUESTION :  Changer la valeur du parametre max_depth. Que se passe-t-il si on prend une valeur trop grande ? Trop petite ? Changer le taux d’éléménts affectés par le bruit (le y[::5]). Quand tous les éléments sont affectés par le bruit, faut-il préférer une valeur élevée ou faible pour max_depth ? Vous pouvez vous aider de la doc de sklearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da4438e4",
      "metadata": {
        "id": "da4438e4"
      },
      "source": [
        "question ouverte pour les plus en avance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f0afe0",
      "metadata": {
        "id": "d3f0afe0"
      },
      "source": [
        "# Sujet du TP : Voir feuille d'exercice TD/TP1\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
